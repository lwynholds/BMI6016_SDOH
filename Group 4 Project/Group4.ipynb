{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9965026f-03a7-42d5-a3f3-032154b2b370",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd6702-03d8-4c12-9c3b-a420ea3c8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import seaborn as sea\n",
    "import geodatasets as gds\n",
    "import fiona #geopandas needs this for shapefiles\n",
    "from geopy.distance import geodesic\n",
    "from matplotlib import colormaps\n",
    "from shapely.geometry import Point\n",
    "\n",
    "pd.set_option('display.max_columns', 70) # Set max display to 70 columns\n",
    "pd.set_option('display.float_format', '{:.0f}'.format) #Causes pandas do NOT output integers as exponents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9db8c-bd8d-4e3f-86e2-f1af2137a64a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importing SDOH et al data, as well as geospatial data (census tract, municipality, and law enforcement boundaries) to join on tract, county or municipality FIPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171071e0-8594-459f-978e-a3e710b74d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahrq_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/SDOH_2020_tract_Utah (reduce to variables).csv\")\n",
    "#AHRQ SDOH variables for Gini Index, Poverty, Median houshold income, Unemployment, Uninsured, Citizenship, Foreign-born, UT population above 1-year-old\n",
    "air_quality_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/annual_conc_by_monitor_2020.csv\") # Air Quality\n",
    "asthma_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/PLACES_Utah_ct_Asthma.csv\") #create Asthma data df on CASTHMA_CrudePrev\n",
    "crime_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/2022crime.csv\") #Crime on \"CRIMES_PER_1K\"\n",
    "resp_haz_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/CancerRisk_by_block_pollutants.csv\") #create Respiratory Hazard data df (group by tract) on \"Total Cancer Risk (per million) \"\n",
    "svi_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/Utah2020SVI (reduce RPL_THEMES).csv\") #Social Vulnerability Index on \"RPL_THEMES\"\n",
    "urban_rural_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/Utah_UAs_Block (group).csv\") #create Urban-Rural data df (group by tract)\n",
    "walkable_df = pd.read_csv(r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/Data Files/Utah_Walkability (reduce).csv\") #Walkability\n",
    "\n",
    "#CENSUS TRACT BASEMAP (which has GEOID20 as well as county FIPS)\n",
    "utct_base = r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/GeoFiles/CensusTracts2020.shp\"\n",
    "utct_base_df = gpd.read_file(utct_base)\n",
    "\n",
    "#MUNICIPALITY BOUNDARIES (which has municipality FIPS)\n",
    "ut_municp = r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/GeoFiles/Municipalities.shp\"\n",
    "ut_municp_df = gpd.read_file(ut_municp)\n",
    "\n",
    "#LAW ENFORCEMENT BOUNDARIES (which has just NAME)\n",
    "utle_base = r\"/Users/kristinknippenberg/My Drive/0_BIOINFORMATICS/BMI 6016 Data Wrangling/Group 4 Project/GeoFiles/LawEnforcementBoundaries.shp\"\n",
    "utle_base_df = gpd.read_file(utle_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253f758",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097534e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put em all in lists: \n",
    "all_dfs = [ahrq_df, air_quality_df, asthma_df, crime_df, resp_haz_df, svi_df, urban_rural_df, ut_municp_df, utct_base_df, utle_base_df, walkable_df]\n",
    "all_df_names = ['ahrq_df', 'air_quality_df', 'asthma_df', 'crime_df', 'resp_haz_df', 'svi_df', 'urban_rural_df', 'ut_municp_df', 'utct_base_df', 'utle_base_df', 'walkable_df']\n",
    "data_dfs = [ahrq_df, air_quality_df, asthma_df, crime_df, resp_haz_df, svi_df, urban_rural_df, walkable_df]\n",
    "data_df_names = ['ahrq_df', 'air_quality_df', 'asthma_df', 'crime_df', 'resp_haz_df', 'svi_df', 'urban_rural_df', 'walkable_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87ffbc",
   "metadata": {},
   "source": [
    "### Convert 'objects' to 'strings' before further manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713969f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we'll get some info\n",
    "for df in all_dfs:\n",
    "    df.info()\n",
    "\n",
    "#The most common reason for an 'object' dtype is that the column holds different types of data. \n",
    "#Pandas is known for using 'object' as a catch-all for columns that don't fit into a specific numeric or string type. \n",
    "#However, a quirk of Pandas is ALSO to label \"string\" datatypes as \"objects.\" \n",
    "#First, We're going to check the dtypes in the object columns.\n",
    "    obj_cols = df.select_dtypes(include='object').columns\n",
    "    for n in obj_cols:\n",
    "        if n in df.columns:\n",
    "            print(f\"{df[n].apply(type).value_counts()}\\n\")\n",
    "            \n",
    "#Now, click anywhere in the output cell, hit 'Ctrl-F', and search for '<class'. You can quickly see if these are all 'str' or can be changed to 'str'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And IF all are strings (spoiler: they are), run code to officially convert all \"object\" datatypes to \"string\" datatypes:\n",
    "for df in all_dfs:\n",
    "    \n",
    "    obj_cols = df.select_dtypes(include='object').columns  \n",
    "    for n in obj_cols:\n",
    "        if n in df.columns:\n",
    "            df[n] = df[n].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85077832",
   "metadata": {},
   "source": [
    "### We're going to delete extraneous data from the data dfs, create some new composite variables, and adjust all the joining variables, making sure these are strings of 11 digits with a label that matches the basemap(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac6702",
   "metadata": {},
   "source": [
    "#### AHRQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slim down the df\n",
    "ahrq_kept_var = ['YEAR', 'TRACTFIPS', 'COUNTYFIPS', 'STATEFIPS', 'STATE', 'COUNTY', 'REGION', 'TERRITORY', 'ACS_TOT_POP_US_ABOVE1', 'ACS_TOT_POP_ABOVE25', 'ACS_PCT_CTZ_US_BORN', 'ACS_PCT_FOREIGN_BORN', 'ACS_PCT_WHITE', 'ACS_PCT_HISPANIC', 'ACS_MEDIAN_HH_INC', 'ACS_PCT_OWNER_HU', 'ACS_PCT_OWNER_HU_COST_30PCT', 'ACS_PCT_RENTER_HU', 'ACS_PCT_RENTER_HU_COST_30PCT', 'ACS_PCT_VACANT_HU', 'ACS_PCT_UNEMPLOY', 'ACS_PCT_UNINSURED', 'ACS_PCT_PERSON_INC_BELOW99', 'ACS_GINI_INDEX', 'ACS_PCT_LT_HS', 'ACS_PCT_HS_GRADUATE', 'ACS_PCT_COLLEGE_ASSOCIATE_DGR', 'ACS_PCT_BACHELOR_DGR', 'ACS_PCT_GRADUATE_DGR']\n",
    "ahrq_dff = ahrq_df[ahrq_kept_var].copy()\n",
    "\n",
    "#Create new variables from old\n",
    "ahrq_dff['ACS_PCT_NONHISP'] = 100-(ahrq_dff['ACS_PCT_HISPANIC']) #Getting % Non-hispanic\n",
    "\n",
    "ahrq_dff['PCT_EDUCATION_WT_AVG'] = (((ahrq_dff['ACS_PCT_LT_HS']*ahrq_dff['ACS_TOT_POP_ABOVE25']*1)+(ahrq_dff['ACS_PCT_HS_GRADUATE']*ahrq_dff['ACS_TOT_POP_ABOVE25']*2)+(ahrq_dff['ACS_PCT_COLLEGE_ASSOCIATE_DGR']*ahrq_dff['ACS_TOT_POP_ABOVE25']*3)+(ahrq_dff['ACS_PCT_BACHELOR_DGR']*ahrq_dff['ACS_TOT_POP_ABOVE25']*4)+(ahrq_dff['ACS_PCT_GRADUATE_DGR']*ahrq_dff['ACS_TOT_POP_ABOVE25']*5))/ahrq_dff['ACS_TOT_POP_ABOVE25'])/100\n",
    "ahrq_dff['PCT_EDUCATION_WT_AVG'] = ahrq_dff['PCT_EDUCATION_WT_AVG'].round(2) #Getting a weighted average of educational attainment, less than HS through graduate degree, for people over age 25\n",
    "\n",
    "#Fix the joining variable and put it near the other variables (it has 11 digits already; just needs to be a string and renamed)\n",
    "ahrq_dff['GEOID20'] = ahrq_dff['TRACTFIPS'].astype('string')\n",
    "ahrq_dff = ahrq_dff[['YEAR', 'GEOID20', 'COUNTYFIPS', 'STATEFIPS', 'STATE', 'COUNTY', ] + [col for col in ahrq_dff.columns if col not in ['YEAR', 'GEOID20', 'COUNTYFIPS', 'STATEFIPS', 'STATE', 'COUNTY', ]]]\n",
    "\n",
    "#ahrq_dff.head()\n",
    "#ahrq_dff.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed95e5",
   "metadata": {},
   "source": [
    "#### Air Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the AQ Data\n",
    "air_quality_df = air_quality_df[air_quality_df['State Code'] == 49] # Utah\n",
    "air_quality_df = air_quality_df[air_quality_df['Parameter Name'] == 'PM2.5 - Local Conditions'] # PM 2.5\n",
    "air_quality_df = air_quality_df[air_quality_df['Pollutant Standard'].isin(['PM25 24-hour 2024', 'PM25 Annual 2024'])] # PM 2.5 standard effective 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77481404",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cad446",
   "metadata": {},
   "outputs": [],
   "source": [
    "utct_base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd83a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utct_base_df.crs)\n",
    "# Convert the utct_base_df GeoDF from EPSG:3857 (NAD83) to EPSG:4326 (WGS 84)\n",
    "# This will match the format of the aq_geo_df\n",
    "utct_base_df = utct_base_df.to_crs(epsg=4326)\n",
    "print(utct_base_df.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40575473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating point geometries from latitude and longitude\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(air_quality_df['Longitude'], air_quality_df['Latitude'])]\n",
    "aq_geo_df = gpd.GeoDataFrame(air_quality_df, geometry=geometry, crs=\"EPSG:4326\")  # The air quality data is in WGS 84 (EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join between the point GeoDF and census tract DF\n",
    "joined_df = gpd.sjoin(aq_geo_df, utct_base_df, predicate='within', how='left') # Using left join to keep all original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract GEOID from joined GeoDF\n",
    "if 'GEOID' in joined_df.columns:\n",
    "    result_df = joined_df[['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC', 'Latitude', 'Longitude', 'GEOID']]\n",
    "elif 'GEOID20' in joined_df.columns:\n",
    "    result_df = joined_df[['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC', 'Latitude', 'Longitude', 'GEOID20']]\n",
    "else:\n",
    "    result_df = joined_df[['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC', 'Latitude', 'Longitude']] # if no GEOID information, keep original data.\n",
    "    print(\"Warning: No GEOID or GEOID20 column found in census tract data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ace44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of joined_df with unique TRACTCE20 values (unique census tracts)\n",
    "joined_df.loc[joined_df.drop_duplicates(subset='TRACTCE20').index].head()\n",
    "joined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46acc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utct_base_df.crs, joined_df.crs)\n",
    "# Convert the utct_base_df GeoDF from EPSG:4326 (WGS 84) back to EPSG:3857 (NAD83), for the sake of the rest of the data and plots\n",
    "# This will match the format of the aq_geo_df\n",
    "utct_base_df = utct_base_df.to_crs(epsg=3857)\n",
    "air_quality_dff = joined_df.to_crs(epsg=3857)\n",
    "print(utct_base_df.crs, air_quality_dff.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feefe57",
   "metadata": {},
   "source": [
    "#### Asthma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bcf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate % of population: \n",
    "asthma_df['CASTHMA_PCT'] = (asthma_df['CASTHMA_CrudePrev']/asthma_df['TotalPopulation']) * 100\n",
    "asthma_df['CASTHMA_PCT'] = asthma_df['CASTHMA_PCT'].round(3)\n",
    "\n",
    "#Fix the joining variable (it has 11 digits already; just needs to be a string and renamed) and put it near the other variables\n",
    "asthma_df['GEOID20'] = asthma_df['TractFIPS'].astype('string')\n",
    "asthma_df = asthma_df[['StateAbbr', 'StateDesc', 'CountyName', 'CountyFIPS', 'GEOID20'] + [col for col in asthma_df.columns if col not in ['StateAbbr', 'StateDesc', 'CountyName', 'CountyFIPS', 'GEOID20']]]\n",
    "\n",
    "#asthma_df.head()\n",
    "#asthma_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5eda0f",
   "metadata": {},
   "source": [
    "#### Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the crime data from counts into 'per 1000':\n",
    "crime_per1K_df = crime_df.copy()\n",
    "\n",
    "for c in crime_per1K_df.columns:\n",
    "    if c not in ['NAME', 'COUNTYFP20', 'FIPS', 'Population']:\n",
    "        crime_per1K_df[c] = (crime_df[c] / crime_df['Population']) *1000\n",
    "\n",
    "#Fix the joining variables (just need to be strings)\n",
    "crime_per1K_df['COUNTYFP20'] = crime_per1K_df['COUNTYFP20'].astype('string')\n",
    "crime_per1K_df['FIPS'] = crime_per1K_df['FIPS'].astype('string')\n",
    "crime_per1K_df['TOT_CRIME_P1K'] = crime_per1K_df['Total']\n",
    "\n",
    "#crime_per1K_df.head()\n",
    "crime_per1K_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb64918a",
   "metadata": {},
   "source": [
    "#### Respiratory Hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48783bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the nature of AIR DATA, I think I'm going to return the maximum value ...\n",
    "resp_haz_max_df = resp_haz_df.groupby('FIPS')['Total Cancer Risk (per million)'].max().reset_index()\n",
    "\n",
    "# ... but it turns out the \"blocks\" roll all the way up to counties (n = 29), not census tracts, as promised. They did a short-cut in 2020. Bleh.\n",
    "# So we're not going to be able to join on the census tracts; we need to join on the counties, which in the census tract basemap, are 3 digit codes.\n",
    "# We will fix the joining variable to be a string and renamed, and we will also slice the values from 5 digits down to 3 by removing the \"49\" prefix.\n",
    "resp_haz_max_df['COUNTYFP20'] = resp_haz_max_df['FIPS'].astype(\"string\")\n",
    "resp_haz_max_df['COUNTYFP20'] = resp_haz_max_df['COUNTYFP20'].str[2:]\n",
    "\n",
    "#And we're going to shorten our data variable:\n",
    "resp_haz_max_df['TCRPM'] = resp_haz_max_df['Total Cancer Risk (per million)'].copy()\n",
    "\n",
    "#Finally we will order the variables\n",
    "resp_haz_max_df = resp_haz_max_df[['FIPS', 'COUNTYFP20', 'Total Cancer Risk (per million)'] + [col for col in resp_haz_max_df.columns if col not in ['FIPS', 'COUNTYFP20', 'Total Cancer Risk (per million)']]]\n",
    "\n",
    "#resp_haz_max_df.head()\n",
    "#resp_haz_max_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1776f2",
   "metadata": {},
   "source": [
    "#### SVI: overall summary ranking and limited English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slim down the df\n",
    "svi_kept_var = ['ST', 'STATE', 'ST_ABBR', 'STCNTY', 'COUNTY', 'FIPS', 'LOCATION', 'AREA_SQMI', 'E_TOTPOP', 'RPL_THEMES', 'EP_LIMENG']\n",
    "svi_dff = svi_df[svi_kept_var].copy()\n",
    "\n",
    "#Fix the joining variable (it has 11 digits already; just needs to be a string and renamed) and put it near the other variables\n",
    "svi_dff['GEOID20'] = svi_dff['FIPS'].astype(\"string\")\n",
    "svi_dff = svi_dff[['ST', 'STATE', 'ST_ABBR', 'STCNTY', 'COUNTY', 'GEOID20'] + [col for col in svi_dff.columns if col not in ['ST', 'STATE', 'ST_ABBR', 'STCNTY', 'COUNTY', 'GEOID20']]]\n",
    "\n",
    "#svi_dff.head()\n",
    "#svi_dff.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cca5a6",
   "metadata": {},
   "source": [
    "#### Urban Areas (only for census-defined \"Urban Areas.\" Any tracts without data are assumed \"rural.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7830935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the joining variables into strings\n",
    "urban_rural_df['STATE'] = urban_rural_df['STATE'].astype('string')\n",
    "urban_rural_df['COUNTY'] = urban_rural_df['COUNTY'].astype('string')\n",
    "urban_rural_df['TRACT'] = urban_rural_df['TRACT'].astype('string')\n",
    "urban_rural_df['UA_POP'] = urban_rural_df['2020_POP'].rename()\n",
    "\n",
    "#Concatenate the above variables into an 11-digit code of the proper name \"GEOID20\"\n",
    "urban_rural_df['GEOID20'] = urban_rural_df['STATE'] + urban_rural_df['COUNTY'].apply(lambda x: str(x).zfill(3)) + urban_rural_df['TRACT'].astype('string')\n",
    "\n",
    "#And put the variables in a preferred order\n",
    "urban_rural_df = urban_rural_df[['STATE', 'COUNTY', 'TRACT', 'GEOID20', 'UA_POP'] + [col for col in urban_rural_df.columns if col not in ['STATE', 'COUNTY', 'TRACT', 'GEOID20', 'UA_POP']]]\n",
    "urban_rural_dff = urban_rural_df.groupby('GEOID20')['UA_POP'].sum().reset_index()\n",
    "\n",
    "#urban_rural_dff.head()\n",
    "#urban_rural_dff.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ef5d7",
   "metadata": {},
   "source": [
    "#### Walkability, rolling up to census tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e49569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the joining variables into strings\n",
    "walkable_df['STATEFP'] = walkable_df['STATEFP'].astype('string')\n",
    "walkable_df['COUNTYFP'] = walkable_df['COUNTYFP'].astype('string')\n",
    "walkable_df['TRACTCE'] = walkable_df['TRACTCE'].astype('string')\n",
    "\n",
    "#Concatenate the above variables into an 11-digit code of the proper name \"GEOID20\"\n",
    "walkable_df['GEOID20'] = walkable_df['STATEFP'] + walkable_df['COUNTYFP'].apply(lambda x: str(x).zfill(3)) + walkable_df['TRACTCE'].apply(lambda x: str(x).zfill(6)).astype('string')\n",
    "\n",
    "#And calculate the mean walkability (rounded to 2 decimals) for each GEOID20\n",
    "walkable_dff = walkable_df.groupby('GEOID20')['NatWalkInd'].mean().reset_index()\n",
    "walkable_dff['NAT_WALK_IND'] = walkable_dff['NatWalkInd'].round(2)\n",
    "\n",
    "#walkable_dff.head()\n",
    "#walkable_dff.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c9e49",
   "metadata": {},
   "source": [
    "### Preparing to Join and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ce1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVISE the lists! \n",
    "all_dfs2 = [ahrq_dff, air_quality_dff, asthma_df, crime_per1K_df, resp_haz_max_df, svi_dff, urban_rural_dff, ut_municp_df, utct_base_df, utle_base_df, walkable_dff]\n",
    "all_df_names2 = ['ahrq_dff', 'air_quality_dff', 'asthma_df', 'crime_per1K_df', 'resp_haz_max_df', 'svi_dff', 'urban_rural_dff', 'ut_municp_df', 'utct_base_df', 'utle_base_df', 'walkable_dff']\n",
    "data_dfs2 = [ahrq_dff, air_quality_dff, asthma_df, crime_per1K_df, resp_haz_max_df, svi_dff, urban_rural_dff, walkable_dff]\n",
    "data_df_names2 = ['ahrq_dff', 'air_quality_dff', 'asthma_df', 'crime_per1K_df', 'resp_haz_max_df', 'svi_dff', 'urban_rural_dff', 'walkable_dff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f2737",
   "metadata": {},
   "source": [
    "### Double-click on me:\n",
    "\n",
    "We've got the following dfs with the following \"JOINING\" variable, the base it joins to, and \"DATA\" variable:\n",
    "\n",
    "DATAFRAME           JOINING_VAR             BASEMAP         DATA_VAR                METRIC\n",
    "ahrq_dff            GEOID20                 utct_base_df    *                       %, MEDIAN, INDEX, WT_AVG\n",
    "air_quality_dff     GEOID20                 utct_base_df    POC                     ????\n",
    "asthma_df           GEOID20                 utct_base_df    CASTHMA_PCT             %\n",
    "crime_per1K_df      NAME,COUNTYFP20,FIPS    all 3           TOT_CRIME_P1K       per 1000\n",
    "resp_haz_max_df     COUNTYFP20              utct_base_df    TCRPM                   Max\n",
    "svi_dff             GEOID20                 utct_base_df    RPL_THEMES,EP_LIMENG    PERCENTILE RANKING,%\n",
    "urban_rural_dff     GEOID20                 utct_base_df    UA_POP                  COUNT\n",
    "walkable_dff        GEOID20                 utct_base_df    NAT_WALK_IND            INDEX\n",
    "\n",
    "*'ACS_PCT_CTZ_US_BORN', 'ACS_PCT_FOREIGN_BORN', 'ACS_PCT_WHITE', 'ACS_PCT_NONHISP', 'ACS_MEDIAN_HH_INC', 'ACS_PCT_OWNER_HU', 'ACS_PCT_OWNER_HU_COST_30PCT', 'ACS_PCT_RENTER_HU', 'ACS_PCT_RENTER_HU_COST_30PCT', 'ACS_PCT_VACANT_HU', 'ACS_PCT_UNEMPLOY', 'ACS_PCT_UNINSURED', 'ACS_PCT_PERSON_INC_BELOW99', 'ACS_GINI_INDEX', 'PCT_EDUCATION_WT_AVG'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0cd8b",
   "metadata": {},
   "source": [
    "### Separate CSVs for combining in SQL or similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bdfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, name in zip(all_dfs2, all_df_names2):\n",
    "    df.to_csv(f\"{name}.csv\", index=False)\n",
    "    \n",
    "#One of us should set this up in SQL and query!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858366a",
   "metadata": {},
   "source": [
    "### Attempting to make one flat CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One CSV\n",
    "\n",
    "one = pd.merge(ahrq_dff[['GEOID20','ACS_PCT_CTZ_US_BORN', 'ACS_PCT_FOREIGN_BORN', 'ACS_PCT_WHITE', 'ACS_PCT_NONHISP', 'ACS_MEDIAN_HH_INC', 'ACS_PCT_OWNER_HU', 'ACS_PCT_OWNER_HU_COST_30PCT', 'ACS_PCT_RENTER_HU', 'ACS_PCT_RENTER_HU_COST_30PCT', 'ACS_PCT_VACANT_HU', 'ACS_PCT_UNEMPLOY', 'ACS_PCT_UNINSURED', 'ACS_PCT_PERSON_INC_BELOW99', 'ACS_GINI_INDEX', 'PCT_EDUCATION_WT_AVG']], asthma_df[['GEOID20', 'CASTHMA_PCT']], on='GEOID20', how='left')\n",
    "\n",
    "one_df = pd.merge(one, svi_dff[['GEOID20', 'RPL_THEMES', 'EP_LIMENG']], on='GEOID20', how='left')\n",
    "\n",
    "one_df_to = pd.merge(one_df, urban_rural_dff[['GEOID20', 'UA_POP']], on='GEOID20', how='left')\n",
    "\n",
    "one_df_to_rule = pd.merge(one_df_to, walkable_dff[['GEOID20', 'NAT_WALK_IND']], on='GEOID20', how='left')\n",
    "\n",
    "one_df_to_rule_them = pd.merge(one_df_to_rule, utct_base_df,on='GEOID20', how='left')\n",
    "\n",
    "one_df_to_rule_them_all = pd.merge(one_df_to_rule_them, resp_haz_max_df, on='COUNTYFP20', how='left')\n",
    "\n",
    "#one_df_to_rule_them_all.info()\n",
    "#one_df_to_rule_them_all.head()\n",
    "#one_df_to_rule_them_all.to_csv('one_df_to_rule_them_all.csv', index=False)\n",
    "\n",
    "#At this point, re the CSV file, Excel is telling me \"This data set is too large for the Excel grid.  If you save this workbook, you'll lose data that wasn't loaded\". I think it's all the geospatial data that's gumming it up.\n",
    "# And I still have to merge the crime data with the LE boundaries and municipalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82cbdc4",
   "metadata": {},
   "source": [
    "### Now we're going to try to develop an easy interface where we can just add/remove different layers and have them show up on the map.\n",
    "#### Plot base layers (census tract and law enforcement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot base layers (census tract and law enforcement) and additional data layers dynamically\n",
    "def ut_base_df(*layers):\n",
    "    ax = utct_base_df.boundary.plot(\n",
    "        figsize=(9,6.5),\n",
    "        linewidth=0.25,\n",
    "        edgecolor=\"000000\",\n",
    "        facecolor='none'\n",
    "        \n",
    "    )\n",
    "    utle_base_df.plot( # Plot the law enforcement map onto Census Tract Map, but make it invisible\n",
    "        ax=ax,  # Plot this dataframe on top of the boundary plot\n",
    "        linewidth=0.25,\n",
    "        edgecolor=\"none\",\n",
    "        facecolor=\"none\"\n",
    "    )\n",
    "    \n",
    "    ax.set_axis_off()  \n",
    "    return ax  # Return the axis to plot further layers on top\n",
    "\n",
    "plt.show(ut_base_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202c4b7",
   "metadata": {},
   "source": [
    "#### Prepare Crime layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_lay = pd.merge(utle_base_df, crime_per1K_df, on='NAME')\n",
    "crime_layer = crime_lay.plot(\n",
    "    column='TOT_CRIME_P1K',\n",
    "    cmap='coolwarm',\n",
    "    alpha=0.6,\n",
    "    legend=True,\n",
    "    edgecolor=\"000000\",\n",
    "    linewidth=0.25,\n",
    "    figsize=(9, 6.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa0d16",
   "metadata": {},
   "source": [
    "#### Prepare the respiratory hazard layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629bfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_haz_lay = pd.merge(utct_base_df, resp_haz_max_df, on='COUNTYFP20')\n",
    "resp_haz_layer = resp_haz_lay.plot(\n",
    "    column='TCRPM',\n",
    "    cmap='coolwarm',\n",
    "    alpha=0.6,\n",
    "    legend=True,\n",
    "    edgecolor=\"000000\",\n",
    "    linewidth=0.25,\n",
    "    figsize=(9, 6.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c7ad8f",
   "metadata": {},
   "source": [
    "#### Prepare the rest of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e1588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['ACS_GINI_INDEX', 'ACS_MEDIAN_HH_INC', 'ACS_PCT_CTZ_US_BORN', 'ACS_PCT_FOREIGN_BORN', 'ACS_PCT_NONHISP', 'ACS_PCT_OWNER_HU', 'ACS_PCT_OWNER_HU_COST_30PCT', 'ACS_PCT_PERSON_INC_BELOW99', 'ACS_PCT_RENTER_HU', 'ACS_PCT_RENTER_HU_COST_30PCT', 'ACS_PCT_UNEMPLOY', 'ACS_PCT_UNINSURED', 'ACS_PCT_VACANT_HU', 'ACS_PCT_WHITE', 'CASTHMA_PCT', 'EP_LIMENG', 'NAT_WALK_IND', 'PCT_EDUCATION_WT_AVG', 'POC', 'RPL_THEMES', 'UA_POP']\n",
    "\n",
    "df_source = [ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, ahrq_dff, asthma_df, svi_dff, walkable_dff, ahrq_dff, air_quality_dff, svi_dff, urban_rural_dff]\n",
    "\n",
    "layers_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, source in zip(layers, df_source):\n",
    "    # Merge dataframes\n",
    "    lay_df = pd.merge(utct_base_df, source[['GEOID20', l]], on='GEOID20', how='left')\n",
    "    \n",
    "    # Plot the data and store the plot object in the dictionary\n",
    "    layer_plot = lay_df.plot(\n",
    "        column=l,\n",
    "        cmap='coolwarm',\n",
    "        alpha=0.6,\n",
    "        legend=True,\n",
    "        edgecolor=\"000000\",\n",
    "        linewidth=0.25,\n",
    "        figsize=(9, 6.5)\n",
    "    )\n",
    "    \n",
    "    # Save the plot object in the dictionary with the layer name as the key\n",
    "    layers_dict[l] = layer_plot\n",
    "\n",
    "# Now layers_dict contains all the plots, and you can access them like layers_dict['ACS_GINI_INDEX'] to view the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ca064",
   "metadata": {},
   "source": [
    "#### Adjust the color-maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68715b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the plot for the 'ACS_GINI_INDEX' layer\n",
    "layer_plot = layers_dict['ACS_GINI_INDEX']  # This is the returned Axes object\n",
    "\n",
    "# Access the collection (which is a list of the plotted shapes or patches)\n",
    "collection = layer_plot.collections[0]  # The first collection is the actual plot\n",
    "\n",
    "# Change the colormap to 'coolwarm'\n",
    "collection.set_cmap('coolwarm')\n",
    "\n",
    "# If needed, also adjust the color limits\n",
    "#collection.set_clim(0, 100)  # Adjust color limits (you can change these values as appropriate)\n",
    "\n",
    "# Optionally, update the colorbar if it was already added\n",
    "layer_plot.figure.colorbar(collection)\n",
    "\n",
    "# Redraw the plot\n",
    "#plt.show()\n",
    "\n",
    "print(layer_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
